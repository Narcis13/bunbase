# Pitfalls: v0.2

**Domain:** Adding user authentication, file uploads, and realtime/SSE to BunBase
**Researched:** 2026-01-26
**Confidence:** HIGH (verified against existing codebase and multiple authoritative sources)

This document catalogs common mistakes when adding user auth, file uploads, and realtime/SSE to an existing backend-in-a-box system that already has admin JWT auth, schema-in-database pattern, auto-generated REST APIs, lifecycle hooks, and single binary compilation.

---

## User Authentication Pitfalls

### 1. JWT Token Type Confusion Between Admin and User

**Risk:** High
**Warning signs:**
- Admin endpoints accepting user tokens (or vice versa)
- Single `requireAdmin` middleware being reused for user auth
- No `type` or `aud` (audience) claim in JWT payloads

**What goes wrong:**
The existing system uses `AdminTokenPayload` with only `adminId`. If user tokens follow the same pattern with just `userId`, there's no way to distinguish token types at verification time. An attacker with a user token could potentially access admin endpoints if the middleware only checks for "valid JWT."

**Prevention:**
1. Add a `type` claim to all JWTs: `{ type: "admin", adminId: "..." }` vs `{ type: "user", userId: "..." }`
2. Create separate middleware: `requireAdmin()` and `requireUser()` that validate the `type` claim
3. Use different JWT secrets or key IDs for admin vs user tokens (defense in depth)
4. Validate `aud` (audience) claim to prevent token reuse across different parts of the API

**Phase:** User Authentication (Phase 1) - Must be designed correctly from the start

**Reference:** [JWT Authorization: Avoiding Common Pitfalls](https://authzed.com/blog/pitfalls-of-jwt-authorization)

---

### 2. Timing Attack on User Enumeration

**Risk:** High
**Warning signs:**
- Login endpoint returns faster for "user not found" than "wrong password"
- Registration endpoint behavior differs for existing vs new emails
- Password reset behaves differently for valid vs invalid emails

**What goes wrong:**
The existing `verifyAdminPassword()` function in `/Users/narcisbrindusescu/newme/bunbase/src/auth/admin.ts` hashes the password only if the admin exists. For user auth at scale, attackers can time requests to enumerate valid email addresses. This leaks which users have accounts.

**Prevention:**
1. Always hash a password even when user doesn't exist:
```typescript
const user = await getUserByEmail(email);
if (!user) {
  // Still hash against a dummy to consume same time
  await Bun.password.verify(password, DUMMY_HASH);
  return null;
}
return await Bun.password.verify(password, user.password_hash) ? user : null;
```
2. Return identical error messages: "Invalid credentials" for both cases
3. Implement rate limiting per IP and per email
4. Use constant-time comparison for any token/string comparisons

**Phase:** User Authentication (Phase 1) - Security critical

**Reference:** [Understanding Timing Attacks](https://blog.propelauth.com/understanding-timing-attacks-with-code/)

---

### 3. Password Hash Work Factor Too Low

**Risk:** Medium
**Warning signs:**
- Using default bcrypt/scrypt parameters without review
- Login feels instantaneous (should take 100-300ms)
- No annual review of hash parameters

**What goes wrong:**
The current admin auth uses `Bun.password.hash()` with defaults. As of 2026, GPU cracking has advanced significantly. Defaults from 2-3 years ago may now be crackable in reasonable time if database is compromised.

**Prevention:**
1. Explicitly set work factor for Bun.password:
```typescript
await Bun.password.hash(password, {
  algorithm: "argon2id",
  memoryCost: 65536,  // 64MB
  timeCost: 3,
});
```
2. Document the hash parameters in code with justification
3. Plan for annual review of parameters
4. Consider implementing password hash upgrades on successful login

**Phase:** User Authentication (Phase 1)

**Reference:** [Password Hashing Guide 2025-2026](https://guptadeepak.com/the-complete-guide-to-password-hashing-argon2-vs-bcrypt-vs-scrypt-vs-pbkdf2-2026/)

---

### 4. Token Revocation Gap (The "New Enemy Problem")

**Risk:** Medium
**Warning signs:**
- No way to force logout a specific user
- Compromised accounts stay active until token expires
- Admin removes user but user's existing tokens still work

**What goes wrong:**
JWTs are stateless. Once issued, they're valid until expiration. If a user's account is suspended/deleted, or their password is changed, existing tokens remain valid. With 24-hour expiration (current admin tokens), that's a long window.

**Prevention:**
1. Shorter token expiration (15-60 minutes) with refresh tokens
2. Implement a token blacklist in SQLite for revoked tokens (check on each request)
3. Add a `tokenVersion` column to users table; increment on password change/logout-all
4. Include `tokenVersion` in JWT; reject if it doesn't match database
5. For critical actions (password change, delete account), require re-authentication

**Phase:** User Authentication (Phase 1 for design, can add revocation list later)

**Reference:** [JWT Authentication: A Tale of Two Tokens](https://chris-gm.medium.com/jwt-authentication-a-tale-of-two-tokens-e3e8028733c9)

---

### 5. Users Collection vs _users System Table Confusion

**Risk:** Medium
**Warning signs:**
- User creates collection named "users" that conflicts with auth
- Password hashes exposed via regular records API
- Auth data mixed with user-defined data

**What goes wrong:**
BunBase uses schema-in-database with `_collections` and `_fields` tables. Users can create any collection via the API. If someone creates a "users" collection, it will conflict with auth users. Additionally, auth user data (password_hash) should NEVER be exposed via the regular records API.

**Prevention:**
1. Store auth users in system table `_users` (like `_admins`), not a regular collection
2. Reserve collection names starting with underscore: reject `createCollection("_anything")`
3. Ensure records API cannot access `_users` table (filter at route level)
4. Create a separate `/api/users/` endpoint for public user profiles (without sensitive fields)
5. Document clearly: "users" collection for app data vs `_users` for auth

**Phase:** User Authentication (Phase 1) - Architecture decision

---

### 6. Email Verification Token Reuse

**Risk:** Medium
**Warning signs:**
- Same verification token works multiple times
- Tokens have no expiration
- Token format is predictable (sequential numbers, user ID encoded)

**What goes wrong:**
If email verification tokens don't expire or can be reused, attackers who intercept a token can use it later. If tokens are predictable, attackers can guess valid tokens.

**Prevention:**
1. Generate cryptographically random tokens (at least 32 bytes)
2. Set short expiration (15-60 minutes)
3. Mark token as used after verification (delete from DB)
4. Hash tokens before storing (compare hashed values)
5. Rate limit verification requests per email

**Phase:** User Authentication (Phase 1)

---

## File Upload Pitfalls

### 7. Relative Path Storage Breaks with Working Directory Changes

**Risk:** High
**Warning signs:**
- File URLs work in dev but break in production
- Files "disappear" when running from different directory
- Single binary deployed to different locations behaves inconsistently

**What goes wrong:**
If files are stored with relative paths (e.g., `uploads/abc123.png`), the resolved location depends on the process's working directory. When running `./bunbase` from `/app`, files go to `/app/uploads`. But when run from `/home/user`, files go to `/home/user/uploads`. The database has relative paths that point to wrong locations.

**Prevention:**
1. Always resolve to absolute paths before storing in database
2. Add a `--storage-path` CLI flag with a default:
```typescript
const storagePath = path.resolve(options.storagePath || "./bunbase_files");
```
3. Store only the relative portion in DB, but always resolve against configured base path
4. Validate storage path exists and is writable on startup
5. Log the resolved storage path on startup for debugging

**Phase:** File Uploads (Phase 2) - Critical for correctness

---

### 8. Embedded Files in Single Binary Are Read-Only

**Risk:** High
**Warning signs:**
- Testing only in dev mode (not compiled binary)
- Assuming `$bunfs/` paths are writable
- Mixing embedded assets with user uploads

**What goes wrong:**
Bun's single-file executable can embed files, but they're stored in memory and "all changes are lost when the executable exits." If the file upload system accidentally tries to write to embedded paths, or if the storage path resolution is wrong, uploads silently fail or disappear on restart.

**Prevention:**
1. Never use embedded paths (`$bunfs/`) for user uploads
2. Always use external filesystem paths for uploads
3. Test the full compiled binary flow, not just `bun run dev`
4. Clear separation: embedded = static assets (admin UI), external = user data
5. Add startup check that storage directory is on real filesystem:
```typescript
if (storagePath.startsWith("$bunfs")) {
  throw new Error("Cannot use embedded filesystem for uploads");
}
```

**Phase:** File Uploads (Phase 2) + Single Binary (verify during packaging)

**Reference:** [Bun Single-File Executables](https://bun.com/docs/bundler/executables)

---

### 9. Multipart Form Data Parsing Issues in Bun

**Risk:** Medium
**Warning signs:**
- File uploads work in Postman but fail from browser
- Intermittent "malformed stream" errors
- Empty `req.files` with express/multer patterns

**What goes wrong:**
Bun has known issues with multipart form data parsing. Bugs include: intermittent `MalformedStreamException`, express+multer returning empty results, and FormData compatibility issues with certain libraries.

**Prevention:**
1. Use Bun's native `req.formData()` method, not express middleware:
```typescript
const formData = await req.formData();
const file = formData.get("file") as Blob;
await Bun.write(storagePath, file);
```
2. Don't manually set `Content-Type: multipart/form-data` on client - let fetch set it
3. Test with actual browser uploads, not just curl/Postman
4. Add error handling specifically for malformed stream errors with retry logic
5. Keep Bun version updated - these bugs are being fixed

**Phase:** File Uploads (Phase 2)

**Reference:** [Multipart formdata issues in Bun](https://github.com/oven-sh/bun/issues/21467)

---

### 10. No File Type Validation Leading to Security Issues

**Risk:** High
**Warning signs:**
- Accepting any file type without validation
- Trusting client-provided MIME type
- Storing files with original filenames

**What goes wrong:**
Without validation, users can upload executable files, scripts, or files with dangerous extensions. If these are later served or accessed, it can lead to XSS (HTML/SVG uploads) or server compromise.

**Prevention:**
1. Validate file extension against allowlist per collection field
2. Check magic bytes, not just MIME type from client:
```typescript
const header = await file.slice(0, 8).arrayBuffer();
const actualType = detectFileType(header);
```
3. Generate random filenames, never use client-provided names
4. Store original filename in database, use generated name on disk
5. Serve files with `Content-Disposition: attachment` or proper `Content-Type`
6. Consider storing files outside web root

**Phase:** File Uploads (Phase 2) - Security critical

**Reference:** [File Upload Vulnerabilities](https://www.vaadata.com/blog/file-upload-vulnerabilities-and-security-best-practices/)

---

### 11. Large File Uploads Causing Memory Exhaustion

**Risk:** Medium
**Warning signs:**
- No file size limits configured
- Server crashes on large uploads
- Memory usage spikes during uploads

**What goes wrong:**
Without limits, a malicious user can upload huge files, exhausting server memory. Bun's `formData()` loads the file into memory. For a backend-in-a-box used by many users, this is a DoS vector.

**Prevention:**
1. Set max file size in field options:
```typescript
{ type: "file", options: { maxSize: 10 * 1024 * 1024 } } // 10MB
```
2. Check Content-Length header before parsing body
3. Stream large files to disk instead of buffering in memory
4. Set overall request body limit at server level
5. Document recommended limits based on use case

**Phase:** File Uploads (Phase 2)

---

### 12. File Deletion on Record Delete Not Implemented

**Risk:** Medium
**Warning signs:**
- Disk usage grows even as records are deleted
- Orphan files accumulating in storage directory
- No cleanup mechanism documented

**What goes wrong:**
If a record with file fields is deleted, but the files remain on disk, storage fills up over time. This is especially problematic for applications with frequent record churn.

**Prevention:**
1. Implement file deletion in `afterDelete` hook for records with file fields
2. Track file-record relationships in database
3. Handle file update (delete old file when new file uploaded)
4. Implement periodic cleanup job for orphaned files
5. Add admin command: `bunbase storage cleanup --orphans`

**Phase:** File Uploads (Phase 2)

---

## Realtime/SSE Pitfalls

### 13. HTTP/1.1 Connection Limit (6 per domain)

**Risk:** High
**Warning signs:**
- "Works on my machine" but users report connection issues
- Multiple tabs cause SSE to stop working
- Mobile browsers worse than desktop

**What goes wrong:**
When not using HTTP/2, browsers limit SSE connections to 6 per domain. If a user opens multiple tabs, or the app opens multiple SSE connections, they hit the limit and connections fail silently or queue indefinitely. This is marked "Won't fix" by Chrome and Firefox.

**Prevention:**
1. Use HTTP/2 (negotiated limit defaults to 100 streams)
2. Multiplex multiple subscriptions over single SSE connection
3. Implement connection sharing across tabs (SharedWorker or BroadcastChannel)
4. Document the limitation for users running without HTTP/2
5. Consider WebSocket fallback for high-connection scenarios

**Phase:** Realtime/SSE (Phase 3)

**Reference:** [MDN Server-Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events)

---

### 14. SSE Memory Leak from Uncleared Connections

**Risk:** High
**Warning signs:**
- Server memory grows over time
- Connection count keeps increasing
- Closed clients still in subscriber list

**What goes wrong:**
When clients disconnect (close tab, lose network), the SSE connection may not properly clean up. If the server maintains a list of subscribers and doesn't remove disconnected ones, memory leaks. Over hours/days, this causes OOM.

**Prevention:**
1. Detect disconnect and remove from subscriber list:
```typescript
req.signal.addEventListener("abort", () => {
  subscribers.delete(clientId);
});
```
2. Implement heartbeat pings to detect stale connections
3. Set max connection lifetime with forced reconnect
4. Log connection count metrics for monitoring
5. Implement max subscribers limit per collection

**Phase:** Realtime/SSE (Phase 3) - Critical for production stability

**Reference:** [Memory Leak with EventSource](https://github.com/expressjs/express/issues/2248)

---

### 15. Raw SQL Queries Don't Fire Realtime Events

**Risk:** High
**Warning signs:**
- Hooks work but SSE events don't fire
- Direct database modifications don't notify clients
- Background jobs update DB but no realtime updates

**What goes wrong:**
The existing hook system (`beforeCreate`, `afterCreate`, etc.) is called from the records API. But if someone uses raw SQL (migrations, background jobs, direct DB access), hooks don't fire. SSE that relies on hooks will miss these changes.

**Prevention:**
1. Document clearly: realtime events require going through records API
2. For background jobs, provide an SDK that uses the records functions
3. Consider database triggers as additional layer (but adds complexity)
4. Alternatively, poll-based sync for critical operations
5. Add a `notifyChange(collection, id, action)` function for manual notification

**Phase:** Realtime/SSE (Phase 3) - Architecture decision

**Reference:** [PocketBase Realtime Discussion](https://github.com/pocketbase/pocketbase/discussions/4427)

---

### 16. Backpressure/Slow Client Causing Server Issues

**Risk:** Medium
**Warning signs:**
- Fast-updating collections cause issues
- Clients on slow networks miss events
- Server memory grows when clients can't keep up

**What goes wrong:**
If the server pushes events faster than a client can consume (slow network, overloaded tab), events queue up. Without backpressure handling, this causes unbounded memory growth or dropped events.

**Prevention:**
1. Implement max event queue size per client (e.g., 100 events)
2. Drop oldest events when queue is full (or disconnect slow client)
3. Batch rapid events (e.g., max 10 events/second per collection)
4. Send last-event-id so clients can request missed events
5. Provide event replay endpoint for catch-up

**Phase:** Realtime/SSE (Phase 3)

**Reference:** [SSE Comprehensive Guide](https://medium.com/@moali314/server-sent-events-a-comprehensive-guide-e4b15d147576)

---

### 17. No Event ID for Reconnection Recovery

**Risk:** Medium
**Warning signs:**
- Clients miss events during brief disconnects
- No way to "catch up" after reconnection
- Data inconsistency between clients

**What goes wrong:**
SSE supports automatic reconnection, but without proper event IDs, clients can't tell the server where they left off. The `Last-Event-ID` header is ignored, and clients miss events that occurred during the disconnect.

**Prevention:**
1. Include incrementing event ID with each SSE message:
```
id: 12345
event: record.create
data: {...}
```
2. Store recent events in memory or database
3. On reconnect, check `Last-Event-ID` header and replay missed events
4. Set reasonable retention period for replay (e.g., 5 minutes)
5. Fall back to full refresh if too many events missed

**Phase:** Realtime/SSE (Phase 3)

**Reference:** [MDN Server-Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events)

---

### 18. SSE Response Format Errors

**Risk:** Low
**Warning signs:**
- EventSource fails to parse events
- `event.data` is undefined on client
- Browser shows SSE connection but no events received

**What goes wrong:**
SSE has a specific text format. Common mistakes include: wrong Content-Type, missing double newlines between events, incorrect field names, or sending JSON as the event name instead of data.

**Prevention:**
1. Always set `Content-Type: text/event-stream`
2. Format events correctly:
```
event: record.create
id: 12345
data: {"collection":"users","record":{...}}

```
3. Double newline (`\n\n`) terminates each event
4. Use `data:` prefix for actual event data
5. Test with browser EventSource, not just curl

**Phase:** Realtime/SSE (Phase 3)

---

## Integration Pitfalls

### 19. Hook System Doesn't Expose Auth Context

**Risk:** Medium
**Warning signs:**
- Hooks can't determine WHO made the change
- No way to implement "created_by" fields automatically
- Audit logging incomplete

**What goes wrong:**
The existing `BaseHookContext` in `/Users/narcisbrindusescu/newme/bunbase/src/types/hooks.ts` has `request?: { method, path, headers }` but no parsed auth information. Hooks would need to re-parse JWT tokens to know the current user, duplicating auth logic.

**Prevention:**
1. Extend hook context with parsed auth:
```typescript
interface BaseHookContext {
  collection: string;
  request?: RequestContext;
  auth?: {
    type: "admin" | "user" | "anonymous";
    id?: string;
    record?: Record<string, unknown>;
  };
}
```
2. Parse auth once in middleware, pass to hook context
3. Document how to access current user in hooks
4. Provide helper: `ctx.isAdmin()`, `ctx.userId`

**Phase:** User Authentication (Phase 1) - Design with hooks integration in mind

---

### 20. Collection API Rules Applied Inconsistently

**Risk:** High
**Warning signs:**
- Records API public but should be restricted
- Admin endpoints accidentally exposed
- Inconsistent auth checks across similar endpoints

**What goes wrong:**
BunBase has admin-only endpoints (`/_/api/`) and public endpoints (`/api/collections/`). Adding user auth creates a third category: "authenticated users." Without a clear rules system (like PocketBase's API rules), it's easy to misconfigure access.

**Prevention:**
1. Design collection-level access rules from the start:
```typescript
{
  listRule: "@request.auth.id != ''",  // Logged-in users
  viewRule: "@request.auth.id != ''",
  createRule: "@request.auth.id != ''",
  updateRule: "id = @request.auth.id",  // Own records only
  deleteRule: null  // Admin only (null = no access)
}
```
2. Default to restrictive (admin-only) not permissive
3. Validate rules at collection creation time
4. Log rule evaluation for debugging
5. Test each endpoint with admin, user, and anonymous requests

**Phase:** User Authentication (Phase 1) - Core architecture decision

---

### 21. File Fields Not Integrated with Cascade Delete

**Risk:** Medium
**Warning signs:**
- Deleting record leaves orphan files on disk
- Disk usage grows even as records are deleted
- No way to track which files belong to which records

**What goes wrong:**
If a record has a file field and the record is deleted, the file remains on disk. Over time, this leads to storage bloat. Similarly, updating a file field should delete the old file.

**Prevention:**
1. Track file ownership in database (record_id, field_name, file_path)
2. Delete files in `afterDelete` hook for file-containing records
3. On file field update, delete previous file
4. Implement storage cleanup job for orphaned files
5. Consider soft-delete for files with delayed cleanup

**Phase:** File Uploads (Phase 2) - Design with lifecycle in mind

---

### 22. Realtime Events Leak Private Data

**Risk:** High
**Warning signs:**
- SSE sends full record data to all subscribers
- No filtering based on user permissions
- Deleted record data included in delete events

**What goes wrong:**
If realtime broadcasts full record data without checking permissions, users could subscribe to a collection and see all records, including ones they shouldn't access. This bypasses API rules.

**Prevention:**
1. Apply same API rules to realtime as to REST API
2. Only send record ID in event, require client to fetch full data
3. Or, filter record data based on subscriber's permissions
4. Never include full record in delete events (just ID)
5. Require authentication for SSE subscriptions (not anonymous)

**Phase:** Realtime/SSE (Phase 3) - Security critical

---

### 23. Single Binary Size Explodes with File Embedding

**Risk:** Low
**Warning signs:**
- Binary size grows unexpectedly
- Build time increases significantly
- Accidentally embedding large test files

**What goes wrong:**
The current build embeds admin UI assets. If file uploads or other large assets are accidentally configured for embedding, binary size balloons. Bun's `$bunfs` is for static assets, not user data.

**Prevention:**
1. Clear separation: embedded = code + admin UI only
2. Review build output size in CI
3. Add size limit check to build script
4. Document what should/shouldn't be embedded
5. Never embed anything from uploads directory

**Phase:** File Uploads (Phase 2) + Build verification

---

### 24. Auth State Not Persisted Across Server Restarts

**Risk:** Low
**Warning signs:**
- Users logged out after server restart
- Sessions lost during deployments
- Inconsistent behavior between dev and production

**What goes wrong:**
If any session state is kept in memory (like token blacklist), it's lost on restart. Users may remain "logged in" on client but server doesn't recognize their tokens.

**Prevention:**
1. JWTs are stateless - this is actually fine for basic auth
2. Store token blacklist in SQLite, not memory
3. Store refresh tokens in database
4. Document expected behavior: "JWT valid until expiry regardless of restarts"

**Phase:** User Authentication (Phase 1)

---

## Phase-Specific Summary

| Phase | Critical Pitfalls | Must Address |
|-------|------------------|--------------|
| **Phase 1: User Auth** | #1 Token Type Confusion, #2 Timing Attack, #5 Users Table Confusion, #19 Hook Auth Context, #20 API Rules | Design JWT claims, timing-safe auth, system table separation |
| **Phase 2: File Uploads** | #7 Relative Paths, #8 Read-Only Embedded, #9 Multipart Issues, #10 Type Validation | Absolute paths, external storage, native FormData, validation |
| **Phase 3: Realtime/SSE** | #13 Connection Limits, #14 Memory Leaks, #15 Raw SQL Misses Events, #22 Data Leakage | HTTP/2, cleanup handlers, hooks-based events, permission filtering |
| **Integration** | #20 API Rules, #21 Cascade Delete, #22 Data Leakage | Unified permission model across REST and SSE |

---

## Checklist Before Implementation

### User Authentication
- [ ] JWT payload includes `type` field to distinguish admin vs user
- [ ] Timing-safe password verification (always hash even for non-existent users)
- [ ] Password hash work factor explicitly configured and documented
- [ ] Users stored in `_users` system table, not regular collection
- [ ] Reserved collection names (underscore prefix) enforced
- [ ] Hook context extended with auth information
- [ ] API rules system designed before implementation

### File Uploads
- [ ] Storage path resolved to absolute path on startup
- [ ] Storage path validated to be external filesystem (not `$bunfs`)
- [ ] Using Bun native `formData()`, not express middleware
- [ ] File type validation against allowlist
- [ ] File size limits enforced
- [ ] File deletion implemented in afterDelete hook
- [ ] Generated filenames used on disk, original stored in DB

### Realtime/SSE
- [ ] HTTP/2 documented as requirement for multiple tabs
- [ ] Connection cleanup on client disconnect implemented
- [ ] Memory leak prevention verified
- [ ] Event IDs included for reconnection recovery
- [ ] Permission filtering applied to events
- [ ] Backpressure handling for slow clients

---

## Sources

- [JWT Authorization: Avoiding Common Pitfalls | AuthZed](https://authzed.com/blog/pitfalls-of-jwt-authorization)
- [7 Ways to Avoid API Security Pitfalls with JWT | 42Crunch](https://42crunch.com/7-ways-to-avoid-jwt-pitfalls/)
- [Understanding Timing Attacks | PropelAuth](https://blog.propelauth.com/understanding-timing-attacks-with-code/)
- [Password Hashing Guide 2025-2026 | Deepak Gupta](https://guptadeepak.com/the-complete-guide-to-password-hashing-argon2-vs-bcrypt-vs-scrypt-vs-pbkdf2-2026/)
- [Bun Single-File Executables](https://bun.com/docs/bundler/executables)
- [Multipart Form Data Issues in Bun | GitHub](https://github.com/oven-sh/bun/issues/21467)
- [File Upload Vulnerabilities | Vaadata](https://www.vaadata.com/blog/file-upload-vulnerabilities-and-security-best-practices/)
- [MDN Server-Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events)
- [SSE Comprehensive Guide | Medium](https://medium.com/@moali314/server-sent-events-a-comprehensive-guide-e4b15d147576)
- [PocketBase Realtime Discussion | GitHub](https://github.com/pocketbase/pocketbase/discussions/4427)
- [Memory Leak with EventSource | Express.js](https://github.com/expressjs/express/issues/2248)
- [PocketBase Authentication Docs](https://pocketbase.io/docs/authentication/)
- [OWASP Authentication Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html)

---

*Last updated: 2026-01-26*
